run.py:
1- handling multiple configs for agents and scenario types

carla_runner:
1- start point
2- handling multiple agents and scenarios in one config
3- assign carla env variables
you can probably find useful information of environment in CarlaDataProvider
Also the self.env attribute in this class is a VectorWrapper for environment details

env_wrapper:
a gym like wrapper carla env.
for accessing to CarlaEnv details: self.env_list[i].get_env().env.__dict__ . full implenentation can be found in gym_carla/envs/carla_env

route_scenario:
1- the manager of one running scenario
2- checks whether the episode has finished


training:
to see saved reward results you can use tools/plot_rewards.py using generated result.pkl file

for adding scenario:
1- duplicate .yaml file in safebench/scenario/config
2- duplicate .json in safebench/scenario/config/scenario_type
3- duplicate a folder in safebench/scenario/scenario_definition and use needed classes
(provided class should be consistent with names in folder safebench/scenario/scenario_data/route/scenarios )


map view:
1- maps are located in safebench/scenario/scenario_data/scenic_data/maps
2- you can use this link for view: https://odrviewer.io/
(note that the y-axis was negated!!!)


viualizing the routes:
1- change directory to tools/CarlaScenariosBuilder
2- read Readme.md in this directory
3- command:  python visualize_routes.py --save_dir ./route --scenario 1
(note that the y-axis was negated!!!)

create route visualy:
python create_routes.py [arguments]
results goes in scenario_origin folder as a .npy file
(needed map names to be added get_map_center function)

create scenarios visualy:
results goes in scenario_origin folder as a .npy file

then export scenarios to safebench
(need some lines to be commented under todo)
(should disable rotation in export_route file)
then copy results to safebench/scenario/scenario_data/route

if episode ends quickly:
1- add --max_episode_step 2000 argument to run command
2- increase timeout in scenario defenition class